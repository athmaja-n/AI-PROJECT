# AI-PROJECT
Application of convolutional neural network  for identification of flower species

Abstract: Automatic identification and recognition of medicinal plant species in environments such as forests, mountains and dense regions is necessary to know about their existence. In recent years, plant species recognition is carried out based on the shape, geometry and texture of various plant parts such as leaves, stem, flowers etc. Flower based plant species identification systems are widely used. While modern search engines provide methods to visually search for a query image that contains a flower, it lacks in robustness because of the intra-class variation among millions of flower species around the world. Hence in this proposed research work, a Deep learning approach using Convolutional Neural Networks (CNN) is used to recognize flower species with high accuracy. Images of the plant species are acquired using the built-in camera module of a mobile phone. Feature extraction of flower images is performed using a Transfer Learning approach (i.e. extraction of complex features from a pre-trained network). A machine learning classifier such as Logistic Regression or Random Forest is used on top of it to yield a higher accuracy rate. This approach helps in minimizing the hardware requirement needed to perform the computationally intensive task of training a CNN. This method for classification of flowers can be implemented in real-time applications and can be used to help botanists for their research as well as camping enthusiasts.

Introduction: Flowers are everywhere around us. They can feed insects, birds, animals and humans. They are also used as medicines for humans and some animals. A good understanding of flowers is essential to help in identifying new or rare species when came across. This will help the medicinal industry to improve. The system proposed in the paper can be used by botanists, campers and doctors alike. This can be extended as an image search solution where photo can be taken as an input instead of text in order to get more information about the subject and search accordingly for best matching results.
Plant identification is an important task for researchers, students, and practitioners in field of the agriculture, forest, biodiversity protection, and so on. Recently, thanks to advanced research in the computer vision community, a number of works have been dedicated to the automatic plant identification based on images of plant organs (e.g., leaf, leafscan, fruit, stem, entire, stem, flower). Among them flower image plays an important role for the plant identification because its appearances (e.g., color, shape, texture) are highly distinguishing. Appearances of flowers are stable and less invariant with weather conditions, age of plant. 
Here, we have compared the performance of two different convolutional neural network architectures one of which is a legacy model and the other is the newest benchmark in the world of object detection and recognition. We have presented our findings in a comparison between the apparent performance of the models.

Overview: For a given RGB image of any flower, our goal is to predict the category of the flower in the image. For this, first the image is segmented using a segmentation method [2]. The background will be removed and the image will have only the subject of interest with no background. These segmented images are then given to the CNN as input images for training. Therefore, the proposed method is divided into two main parts; segmentation and fine-tuning the deep convolutional neural network. For fine-tuning the CNN, we have used the ImageNet ILSVRC pre-trained models submitted to the competition.
Flower images are normally captured on complicated background with the presence of different objects. Even, CNN can be applied directly on these images, in this paper, in order to evaluate the effect of background for flower identification; we deploy some preprocessing techniques on flower images. The results extract only flower regions from a natural image. 

Scope: We have  developed  a  deep  learning  network  forclassification of  different  flowers. For  this, we  have  used  VisualGeometry  Group’s  102  category  flower  data-set  having  8189images of  102  categories  from  Oxford University. The method isbasically  divided  in  two  parts  i.e.  Image  segmentation  andclassification.  We  have  compared  two  different  ConvolutionalNeural  Network  architectures  GoogLeNet  and  AlexNet  for  theclassification  purposeThis method for classification of flowers  can  be  implemented  in  real-time  applications  and  can  be  used  to  help  botanists  for  their research as well as camping enthusiasts. 

Objectives : The aim of classification is to place the flowers into a hierarchy of ranks or categories such as species, genera, families and so on. In addition to expressing relationship based on common features, classification serves as a filing and information retrieval system and allows easier reference to organisms comprising the filing system i.e. it provides an idea about the sequence of evolution of flowers from simple to more complex and from more primitive to more advanced types.

Problem Statement: Flower classification is a challenging task due to the wide range of flower species which have similar shape, appearance or surrounding objects such as leaves and grass. In this paper, we propose a novel two-step deep learning classifier to distinguish flowers of a wide range of species. Firstly, the flower region is automatically segmented to allow localisation of the minimum bounding box around it.
Unlike simple object classification such as distinguishing cats from dogs, flower recognition and classification are a challenging task due to the wide range of flower classes that share similar features: Several flowers from different types share similar colour, shape and appearance. Furthermore, images of different flowers usually contain similar surrounding objects such as leaves, grass, etc. There are more than 250000 known species of flowering plants classified into about 350 families.
A wide range of various applications including content-based image retrieval for flower representation and indexing, plants monitoring systems, floriculture industry, live plant identification and educational resources on flower taxonomy depend on successful flower classification. Manual classification is possible but time consuming and tedious to use with a large number of images and potentially erroneous in some flower classes especially when the image background is complex. Thus, robust techniques of flower segmentation, detection and classification have great value.

Literature survey:
In views of the botanic experts, flower images therefore are most valuable source for the plant identification task. However, to develop an automatic plant identification system based on flower images, the proposing techniques face to many challenges such as large inter-class similarity, but small intra-class similarity, lighting and viewpoint variations, occlusion, clutter, and object deformations [1].
As the classification of flower species is an important task, it is already in research and many different approaches have been developed. Previously, methods like Deformable Part Models [2], Histogram of Oriented Gradients [3] and Scale invariant feature transform [4] were used for feature extraction, linear classifiers and object detectors [5]. 
Later the work was focused onsegmentation and classification using manual feature engineering. But nowadays, state-of-art performance is achieved by Convolutional Neural Networks. CNNs have fulfilled the demand of robustness and have removed the need of hand crafted features. They are similar to Artificial Neural networks but does not require feature engineering. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linear operation. At the last, CNNs also have a loss function which is to be minimized for optimization.For using CNNs, a large amount of data is required for training. 
We have used the Visual Geometry Group’s 102 category flower data-set used in [6] having 8,189 images spread over 102 categories from Oxford University. We split 15% of the total images for validation set and 15% for test set. Due to the large amount of data needed for CNNs, 8,189 images are not sufficient for training. Hence, we are using pre-trained models which are trained on ILSVRC2012 Dataset and fine-tuning them on the Oxford data-set. This makes the application less computational expensive.
A novel approach to recognize and identify plants using shape, color and texture features combined with Zernike moments with Radial Basis Probabilistic Neural Networks (RBPNN) was proposed by Kulkarni et al [7]. A flower classification approach based on vocabulary of texture, color and shape features was proposed by Zisserman and tested on 103 classes [8]-[9]. To accurately recognize flowers in images, Salahuddin et al. proposed a segmentation approach that uses color clustering and domain knowledge of flowers [10].

